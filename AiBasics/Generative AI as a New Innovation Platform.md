Michael Cusumano: Hello,
I'm Michael Cusumano, a professor and currently
Deputy Dean for Faculty at the MIT Sloan
School of Management. In this video, which is based
on a column I wrote for Communications of the
ACM in October 2023, we'll explore a
potential game changer in the digital world: the emergence of generative AI as a new innovation platform. Now, what's an
innovation platform? It's a foundational
technology with products and services
built on top of it. Examples include
operating systems like Microsoft Windows, Apple iOS, and Google Android, as well as broader system platforms like personal computers
and smartphones. With innovation
platforms, you'll often see network effects. To start, third parties create their own products and services accessed through the platform. More applications
attract more users, which leads to more applications
and even more users. The platform becomes
increasingly valuable with these networks
of users and applications. Growth in usage then enables continual improvements in
the foundational technology. Now, generative AI
shows signs of becoming a powerful enabling technology
and innovation platform, but it isn't fully there yet. The foundation models
are rapidly evolving, but there's still no
one dominant player. However, the technology
has advanced enough to support a growing
ecosystem of applications, infrastructure providers,
and specialized use cases. Let's look at how generative AI emerged as a new
platform technology. Artificial intelligence
and machine learning has taken decades to develop, but some recent events have
been especially important. In 2017, researchers at Google published a
key paper showing how neural networks could
analyze and then predict language patterns rather
than just individual words. Those researchers went
on to firms like OpenAI. Then, OpenAI introduced GPT-3 in 2020 and ChatGPT in 2022. These new tools brought generative AI into
the mainstream. This whole class of systems can "generate" text,
graphics, audio, and video using learning algorithms based on large
language models, or LLMs, that train
on huge datasets, almost whole languages. The potential
applications are vast. Now, a huge class of generative
AI systems has emerged. Several hundred start-ups
already target the space. Generative AI
hardware and software currently comprise a
$40 billion market, and Bloomberg projects
that it could grow to over one trillion dollars
over the next decade. Now, the generative AI ecosystem
has three main layers. First, the foundational models and related development
or programming tools. Users can access
generative AI chatbots through Internet browsers, but the underlying
computing environment is the LLM software. The major players in this
space include OpenAI and Microsoft with
ChatGPT and Bing, Google with DeepMind, Bard, and AlphaFold, and
Meta with Llama 2. Second, there's the
specialized infrastructure needed to run
generative AI systems. These models require GPU chips, optimized for
parallel processing. NVIDIA leads in the GPU space, while cloud giants like AWS, Microsoft Azure, and Google provide the data
center infrastructure. Third, we have applications
for users and developers. For example, Microsoft and Google added LLMs to
their search engines, providing easy access to this technology for
billions of people. You'll also find vertical
start-ups targeting use cases across products and services for manufacturing, healthcare, finance,
media, construction, agriculture, and more. In summary, foundational models and development
tools set the stage, infrastructure powers them, and applications realize
their potential. However, this brings us
to our next question: what are the risks posed by widespread deployment
of generative AI? For one, concentration of market power is
almost inevitable. Given platform dynamics
with network effects, and the enormous
financial resources required to develop
and run these systems, we're likely to
see consolidation down to just the
biggest tech giants. Second is content
ownership and privacy. Generative AI models train on data scraped from
the public web. Some scraping has been
allowed for search engines, but courts and
legislators will have to answer the new
trillion-dollar question: What is fair use of training data for
generative AI systems? Then there are
rising concerns over information accuracy
and authenticity. We know there is a lot
of bias built into AI algorithms based on the data they train on and the
people who build them. Also, when LLMs cannot
find an answer to a query, they use predictive analytics to make up reasonable responses, but sometimes they
are incorrect. These "hallucinations" currently limit potential applications. There are questions around self-regulation versus
government oversight, as well. A collaborative approach between industry leaders, policymakers, and experts to establish ethical norms is essential to help guide
responsible development. The environmental impact of these technologies
is rising fast. By some estimates, generative AI's use of computing
resources has been increasing exponentially
for years and already has become an enormous use of
energy in data centers. Then there are
unintended consequences. For example, these
technologies could replace, enhance, or greatly alter many human jobs and occupations
for better or for worse. In closing, generative AI
should bring many positives, but we have to manage
this increasingly powerful technology
very carefully. With models advancing
so rapidly, this new platform can
potentially transform everything from
scientific discovery to education and business. Industry, government, and company leaders will
need to collaborate closely to establish guardrails for
responsible innovation. The future of this
technology is just emerging, and so this is the moment to shape
what comes next.
